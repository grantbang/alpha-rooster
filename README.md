# Project Alpha Rooster: Master Specification

**Version:** 8.0 (Methodical Execution Build)  
**Classification:** Autonomous Programmatic Arbitrage Engine  
**Target Infrastructure:** Google Cloud Platform (GCP)  
**Core Logic:** Closed-Loop Yield Optimization

---

## Part 1: The Functional Abstract (The Narrative)

### 1.1 The Business Intent

Project Alpha Rooster is a financial machine designed to provide liquidity to the digital advertising market. It functions as an Autonomous Arbitrage Router.

The system identifies "mispriced assets" in the form of search keywords. It exploits the spread between the cost to acquire a user on a demand platform (Google Ads) and the revenue generated by that user on a supply platform (Commercial Ad Feeds). It is not a marketing tool; it is a capital allocation engine.

### 1.2 The "Unity" of the System (The 4-Stage Loop)

The application operates as a single, continuous production line. Every component exists to service this closed loop:

#### Selection (The Discovery Phase)

**Logic:** Before spending capital, the system scans the market. It compares the Supply Payout (e.g., "Crypto offers pay $4.00") against the Demand Cost (e.g., "Crypto traffic costs $0.50").

**Action:** If Payout > Cost, the keyword is "Selected" and queued for funding.

#### Ingestion (The Buy Phase)

**Logic:** The system allocates a daily budget to the Selected Keywords on Google Ads.

**Action:** It buys a specific user visit (a "Click").

#### Transformation (The Bridge Phase)

**Logic:** The user lands on our serverless Bridge App.

**Action A (Asset Tagging):** The app attaches a Financial Tracker ID (gclid) to the user session. This turns an anonymous visitor into a unique, trackable asset.

**Action B (Contextualization):** The app uses Vertex AI to generate a helpful summary of the user's problem to ensure relevance.

**Action C (Routing):** The app presents high-value Commercial Offers from the Feed Provider.

#### Yield (The Optimization Phase)

**Logic:** The user clicks an offer, generating revenue. The Feed Provider reports the value of that specific Tracker ID back to us.

**Action:** The system reconciles the Ledger.

- **If Profitable:** The system automatically scales the budget for that keyword.
- **If Unprofitable:** The system automatically kills the keyword to preserve capital.

### 1.3 High-Level Conceptual Flow

```mermaid
graph TD
    subgraph STAGE_1_SELECTION
    Supply[Feed API<br/>High Payouts]
    Demand[Google Planner<br/>Low Costs]
    GapLogic{Is Spread > 200%?}
    TargetList[Selected Assets]
    end

    subgraph STAGE_2_INGESTION
    Capital[Daily Budget]
    AdsPlatform[Google Ads]
    User[User Visit]
    end

    subgraph STAGE_3_TRANSFORMATION
    Bridge[Bridge App]
    Tracker[Assign Tracker ID<br/>(GCLID)]
    AI[AI Context Gen]
    end

    subgraph STAGE_4_YIELD
    Revenue[Revenue Event]
    Ledger[BigQuery Ledger]
    Bot[Optimizer Bot]
    end

    Supply & Demand --> GapLogic
    GapLogic -- YES --> TargetList
    TargetList --> AdsPlatform
    Capital --> AdsPlatform
    AdsPlatform --> User
    User --> Bridge
    Bridge --> Tracker
    Tracker --> AI
    Tracker --> Revenue
    Revenue --> Ledger
    Ledger --> Bot
    Bot -->|Scale Winners| AdsPlatform
    Bot -->|Kill Losers| AdsPlatform
```

---

## Part 2: Atomic Technical Specification (The Blueprint)

> **Directive for Coding Agent:** This is the immutable technical specification. Do not deviate from schema definitions, variable names, or logic gates.

### 2.1 Technology Stack & Constraints

| Component | Technology | Hard Constraint |
|-----------|------------|-----------------|
| Compute | Cloud Run | Python 3.11, FastAPI. Min instances: 0 (Cost). Max: 50. |
| Orchestration | Cloud Composer | Airflow 2.5+. |
| Database | BigQuery | Standard SQL. Partitioned by DATE(event_time). |
| AI Model | Vertex AI | gemini-1.5-flash (Optimized for speed/cost). Timeout: 1.5s. |
| Supply API | Tonic / System1 | Must support subid pass-through. |
| Demand API | Google Ads API | v17+. |

### 2.2 Data Architecture (The Source of Truth)

**Dataset:** `alpha_rooster_v1`

#### Table A: `ledger_cost` (Immutable Spend Log)

**Source:** Google Ads API (search_term_view)  
**Primary Key:** tracker_id (Mapped from click_view.gclid)

**Schema:**
- `tracker_id` (STRING, REQUIRED)
- `campaign_id` (STRING)
- `keyword_text` (STRING)
- `cost_micros` (INT64)
- `ingested_at` (TIMESTAMP)

#### Table B: `ledger_revenue` (Immutable Yield Log)

**Source:** Feed Provider API  
**Foreign Key:** tracker_id (Mapped from subid4)

**Schema:**
- `tracker_id` (STRING, REQUIRED)
- `offer_id` (STRING)
- `revenue_amount` (FLOAT64)
- `conversion_time` (TIMESTAMP)

#### View: `view_alpha_matrix` (The Decision Engine)

```sql
SELECT
    c.keyword_text,
    c.campaign_id,
    COUNT(c.tracker_id) as volume,
    SUM(c.cost_micros / 1000000) as total_spend,
    COALESCE(SUM(r.revenue_amount), 0) as total_yield,
    -- ROI Logic with Safety Division
    SAFE_DIVIDE(
        (COALESCE(SUM(r.revenue_amount), 0) - SUM(c.cost_micros / 1000000)),
        SUM(c.cost_micros / 1000000)
    ) as roi_factor
FROM `alpha_rooster_v1.ledger_cost` c
LEFT JOIN `alpha_rooster_v1.ledger_revenue` r
    ON c.tracker_id = r.tracker_id
WHERE c.ingested_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
GROUP BY 1, 2
HAVING volume > 5
```

### 2.3 Component Specs

#### Component 1: The Discovery Engine (`/discovery`)

**Role:** Identifies keywords to buy.

**Logic:**
1. Call Feed API: Get categories where EPC > $2.00.
2. Call Google Ads Planner: Get AvgCPC for keywords in those categories.
3. Selection Rule: IF (EPC / AvgCPC) > 2.0 THEN Add to Target_List.

**Output:** A BigQuery table `target_opportunities`.

#### Component 2: The Bridge App (`/app`)

**Role:** Transforms traffic and tracks assets.

**Route:** `GET /router?q={keyword}&gclid={id}`

**Atomic Logic:**
1. **Tracker Validation:** IF gclid is missing, generate UUID (Fail Open) & Log Warning.
2. **AI Context:** Call Vertex AI. Prompt: "Write 2 sentences defining '{q}' for a consumer." Timeout: 1.5s.
3. **Feed Fetch:** Call Feed API. CRITICAL: Pass gclid into subid4 parameter.
4. **Render:** Return Jinja2 HTML with `{{ context }}` and `{{ feed_results }}`.

#### Component 3: The Optimizer Bot (`/bot`)

**Role:** Autonomous Capital Allocation.

**Schedule:** Every 4 Hours via Airflow.

**Logic Rules:**
- **Kill Switch:** IF `total_spend > $15.00` AND `roi_factor < -0.40` (Loss > 40%) → Action: PAUSE_KEYWORD.
- **Scale Winner:** IF `total_spend > $40.00` AND `roi_factor > 0.30` (Profit > 30%) → Action: INCREASE_BID(10%).
- **Safety Cap:** IF `SUM(daily_spend) > $200.00` → Action: ABORT & ALERT.

---

## Part 3: Low-Grain Execution Checklist

Use this checklist to track progress. Do not proceed to the next phase until all items in the current phase are checked.

### Phase 1: Foundation (Infrastructure)

- [ ] **1.1 GCP Setup:** Create Project `alpha-rooster`. Enable APIs: Run, Build, BigQuery, Composer, Vertex AI.
- [ ] **1.2 IAM Setup:** Create Service Account `rooster-core-sa`. Assign roles: BigQuery Admin, Storage Admin, Vertex AI User, Cloud Run Invoker.
- [ ] **1.3 Local Env:** Set up local directory structure (`/infra`, `/app`, `/dags`). Create virtual environment (venv).
- [ ] **1.4 Database Init:** Create `schema.sql` with the DDL for `ledger_cost`, `ledger_revenue`, and `view_alpha_matrix`.
- [ ] **1.5 Validation:** Run the SQL against BigQuery. Confirm the empty tables and view exist in the console.

### Phase 2: The Bridge (Application)

- [ ] **2.1 Scaffold:** Initialize FastAPI app in `/app`. Install fastapi, uvicorn, jinja2.
- [ ] **2.2 Logic - Tracker:** Implement `extract_gclid()` function. Test: Verify it returns a UUID if gclid is missing.
- [ ] **2.3 Logic - AI:** Implement `get_ai_context()` using Vertex SDK. Test: Run a script to print a summary of "bitcoin".
- [ ] **2.4 Logic - Feed:** Implement `get_feed_offers()` (Mock initially). Test: Verify subid4 receives the gclid.
- [ ] **2.5 HTML:** Create `templates/index.html`. Ensure "Privacy Policy" link exists (Compliance).
- [ ] **2.6 Deploy:** Create Dockerfile. Deploy to Cloud Run.
- [ ] **2.7 Validation:** Curl the public URL with `?q=test&gclid=123`. Verify 200 OK and HTML response.

### Phase 3: The Data (Ingestion)

- [ ] **3.1 Credentials:** Download Google Ads API YAML and Feed API Keys. Store in Secret Manager (or .env for dev).
- [ ] **3.2 Connector - Ads:** Write `utils/google_ads_client.py`. Test: Fetch cost_micros for yesterday (even if 0).
- [ ] **3.3 Connector - Feed:** Write `utils/feed_client.py`. Test: Fetch revenue report JSON.
- [ ] **3.4 Pipeline:** Create `dags/sync_ledgers.py`. Implement the logic to insert API data into BigQuery.
- [ ] **3.5 Validation:** Manually trigger the DAG. Check BigQuery `ledger_cost`. Verify rows appear.

### Phase 4: The Brain (Optimization)

- [ ] **4.1 Logic - Kill:** Write function `check_kill_conditions()`. Input: roi_factor. Output: Boolean.
- [ ] **4.2 Logic - Scale:** Write function `check_scale_conditions()`. Input: roi_factor. Output: Boolean.
- [ ] **4.3 Connector - Mutate:** Add `pause_keyword()` and `increase_bid()` methods to Ads Client.
- [ ] **4.4 Safety:** Implement `check_daily_cap()`. Test: Force variable to $201 and verify script aborts.
- [ ] **4.5 Validation:** Run the Optimizer DAG in "Dry Run" mode (logging only). Verify logs show correct "Kill/Scale" decisions based on dummy data.